{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T12:49:47.029400Z",
     "start_time": "2025-05-21T12:49:47.027364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import esm\n",
    "import re\n",
    "from transformers import BertForMaskedLM, BertTokenizer, pipeline"
   ],
   "id": "e859fb132b7b3e35",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T12:49:57.747938Z",
     "start_time": "2025-05-21T12:49:47.754883Z"
    }
   },
   "cell_type": "code",
   "source": "model, alphabet = esm.pretrained.esm1b_t33_650M_UR50S()",
   "id": "ee8e7f7c25b0567b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T12:49:57.806543Z",
     "start_time": "2025-05-21T12:49:57.795716Z"
    }
   },
   "cell_type": "code",
   "source": "sequence = \"MSHHWGYGKHNGPEHWHKDFPIAKGERQSPVDIDTHTAKYDPSLKPLSVSYDQATSLRILNNGHAFNVEFDDSQDKAVLKGGPLDGTYRLIQFHFHWGSLDGQGSEHTVDKKKYAAELHLVHWNTKYGDFGKAVQQPDGLAVLGIFLKVGSAKPGLQKVVDVLDSIKTKGKSADFTNFDPRGLLPESLDYWTYPGSLTTPPLLECVTWIVLKEPISVSSEQVLKFRKLNFNGEGEPEELMVDNWRPAQPLKNRQIKASFK\"\n",
   "id": "edbc22be8aab553f",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T12:52:19.703410Z",
     "start_time": "2025-05-21T12:52:19.695259Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_protbert_embedding(seq):\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    tokenizer = BertTokenizer.from_pretrained('Rostlab/prot_bert_bfd', do_lower_case=False )\n",
    "    model = BertForMaskedLM.from_pretrained(\"Rostlab/prot_bert_bfd\").to(device)\n",
    "    seq1 = \" \".join(list(re.sub(r\"[UZOB]\", \"X\", seq)))\n",
    "\n",
    "    ids = tokenizer(seq1, return_tensors='pt')\n",
    "    input_ids = torch.tensor(ids['input_ids']).to(device)\n",
    "    attention_mask = torch.tensor(ids['attention_mask']).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    output1 = output[0][0][1: -1]\n",
    "    assert len(seq) == len(output1)\n",
    "\n",
    "    return output1.cpu()\n"
   ],
   "id": "9523cfd50379962f",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T13:01:44.355951Z",
     "start_time": "2025-05-21T13:01:40.741461Z"
    }
   },
   "cell_type": "code",
   "source": "emb = get_protbert_embedding(sequence)",
   "id": "3ea1dcd9e598da86",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Rostlab/prot_bert_bfd were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/var/folders/7s/g4dz7t0n7mq_r8hp256vj64c0000gq/T/ipykernel_30802/4117202380.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(ids['input_ids']).to(device)\n",
      "/var/folders/7s/g4dz7t0n7mq_r8hp256vj64c0000gq/T/ipykernel_30802/4117202380.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(ids['attention_mask']).to(device)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T13:02:04.077925Z",
     "start_time": "2025-05-21T13:02:04.072268Z"
    }
   },
   "cell_type": "code",
   "source": "emb.numpy()",
   "id": "ff42a690c9e3950c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-23.859938, -23.815985, -22.31545 , ..., -23.226543, -24.34729 ,\n",
       "        -24.115314],\n",
       "       [-22.448683, -21.592663, -19.956684, ..., -20.410755, -23.648851,\n",
       "        -21.061636],\n",
       "       [-24.209427, -22.984352, -23.723406, ..., -24.250395, -22.882277,\n",
       "        -22.849083],\n",
       "       ...,\n",
       "       [-22.058775, -23.30712 , -20.929007, ..., -20.387453, -23.054655,\n",
       "        -22.220621],\n",
       "       [-21.16265 , -22.80935 , -21.44013 , ..., -20.688042, -24.13068 ,\n",
       "        -22.769648],\n",
       "       [-22.84188 , -23.127182, -23.31618 , ..., -22.15452 , -22.406187,\n",
       "        -22.116007]], shape=(260, 30), dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1254c9739b4b5d18"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
